{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ab7413",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temperatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: final_response}\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Iterate over the different temperature settings\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp \u001b[38;5;129;01min\u001b[39;00m temperatures:\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Repeat the whole experiment n times\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NrOfExper):\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temperatures' is not defined"
     ]
    }
   ],
   "source": [
    "def run_TVDL_strategy(system_message, training_data, iterate_prompt,context_prompt, conversation_dropdown):\n",
    "    class AssistantResponse:\n",
    "        def __init__(self, role, content):\n",
    "            self.role = role\n",
    "            self.content = content\n",
    "    # Initialize list to store predicted strengths and corresponding formulations\n",
    "    predictions = []\n",
    "    unique_formulations = []\n",
    "\n",
    "    # Start with the system message\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message}\n",
    "    ]\n",
    "    \n",
    "    # Add training data and iteration prompt\n",
    "    if training_data:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": \"Previously, we have tested these formulations with the following result:\\n\" + \"\\n\".join(training_data)})\n",
    "        messages.append({\"role\": \"user\", \"content\": iterate_prompt})\n",
    "        training_formulations = extract_formulations_from_training_data(training_data)\n",
    "    # Add the new user prompt to ask for three unique formulations\n",
    "    messages.append({\"role\": \"user\", \"content\": \"Output 3 three different unique formulations with a extremly high expected compressive strength. Make sure they lie on the allowed parameter grid but have not been tested previously.\"})\n",
    "    \n",
    "    # Make API call\n",
    "    assistant_response = call_openai_api(messages, temp)\n",
    "    \n",
    "    # Extract the three formulations\n",
    "    response_lines = assistant_response.choices[0].message.content.split('\\n')\n",
    "    # Define a regular expression pattern to capture the relevant information\n",
    "    pattern = re.compile(r'Powderkg\\s*=\\s*(\\d+),\\s*wc\\s*=\\s*(\\d+\\.\\d+),\\s*materials\\s*=\\s*(\\d+\\.\\d+/\\d+\\.\\d+),\\s*curing\\s*=\\s*(\\w+)', re.IGNORECASE)\n",
    "    \n",
    "    # Use list comprehension to find all matches in the response lines\n",
    "    formulations = [match.group(0) for line in response_lines for match in [pattern.search(line)] if match]\n",
    "    #formulations = [line for line in response_lines if line.startswith(\"The formulation is\")]\n",
    "    if training_data:\n",
    "        unique_formulations = [f for f in formulations if f not in training_formulations]\n",
    "        if len(unique_formulations) == 0:\n",
    "            print('no new formulations extracted')\n",
    "        formulations = unique_formulations        \n",
    "    # Handle the case where all suggested formulations are duplicates\n",
    "    # Maybe prompt the assistant again or take other actions\n",
    "\n",
    "    if conversation_dropdown.value == 'Complete':\n",
    "        print('####', response_lines)\n",
    "        print(\"Extracted Formulations:\", formulations)\n",
    "    \n",
    "    # Prepare the forward task prompt\n",
    "\n",
    "    forward_prompt_base = f\"{context_prompt} {training_data} You are a powerful concrete strength prediction model. You can take into account design rules and the outcome of previous lab validation to predict the compressive strength of untested novel formulations. Answer in this exact format with a single number only 'The Predicted Strength is {{your Answer}} MPa.'\"\n",
    "    \n",
    "    for formulation in formulations:\n",
    "        # Create the full forward task prompt\n",
    "        forward_prompt = f\"{forward_prompt_base}\\n Given these examples, what is the compressive strength of {formulation}?\"\n",
    "        \n",
    "        if conversation_dropdown.value == 'Complete':\n",
    "            print(\"Forward Prompt:\", forward_prompt)\n",
    "        \n",
    "        # Make the API call to get the forward task prediction\n",
    "        forward_response = call_openai_api([{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": forward_prompt}], 0)\n",
    "        \n",
    "        # Extract the predicted strength from the model's response\n",
    "        try:\n",
    "            predicted_strength_str = forward_response.choices[0].message.content.split(' ')[-2]\n",
    "            predicted_strength = float(predicted_strength_str)\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert predicted strength for {formulation} to float. Skipping this formulation.\")\n",
    "            continue\n",
    "        \n",
    "        if conversation_dropdown.value == 'Complete':\n",
    "            print(f\"Predicted Strength for {formulation}: {predicted_strength} MPa\")\n",
    "        \n",
    "        # Append to the predictions list\n",
    "        predictions.append((formulation, predicted_strength))\n",
    "    \n",
    "    # Handle case where predictions list is empty\n",
    "    if not predictions:\n",
    "        print(\"No valid predictions were made. Defaulting to the first formulation.\")\n",
    "        return {'role': 'assistant', 'content': formulations[0] if formulations else 'Unable to make valid predictions.'}\n",
    "    \n",
    "    # Select the formulation with the highest predicted strength\n",
    "    final_response, best_strength = max(predictions, key=lambda x: x[1])\n",
    "    \n",
    "    # Return an instance of AssistantResponse\n",
    "    return AssistantResponse('assistant', final_response)\n",
    "\n",
    "# Iterate over the different temperature settings\n",
    "for temp in temperatures:\n",
    "\n",
    "    # Repeat the whole experiment n times\n",
    "    for experiment in range(NrOfExper):\n",
    "        print(f\"\\n---\\nStarting experiment {experiment+1}...\\n---\")\n",
    "        training_data = []\n",
    "        current_strength = 0.0\n",
    "        iterations = 0\n",
    "        formulations=[]\n",
    "        # System message including both the role prompt and context\n",
    "        system_message = system_role_prompt.value  + '\\n' + context_prompt.value\n",
    "\n",
    "        while iterations < budget:\n",
    "            iterations += 1\n",
    "            print(f\"\\n---\\nStarting iteration {iterations} at temp {temp}...\")\n",
    "\n",
    "            # Start with the system message\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message}\n",
    "            ]\n",
    "\n",
    "            # Add the training data to the messages\n",
    "            if training_data:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": \"Previously, we have tested these formulations with the following result:\\n\" + \"\\n\".join(training_data)})\n",
    "                # Add the iteration prompt\n",
    "                messages.append({\"role\": \"user\", \"content\": iterate_prompt.value})\n",
    "                \n",
    "            if conversation_dropdown.value == 'Complete':\n",
    "                print(\"--- Conversation History ---\")\n",
    "                for msg in messages:\n",
    "                    print(f\"{msg['role']}: {msg['content']}\")\n",
    "\n",
    "            valid_solution = False\n",
    "            while not valid_solution:\n",
    "                if enable_TVDL_strategy == 1:  # Assuming '1' means enabled\n",
    "                    assistant_response = run_TVDL_strategy(system_message, training_data,iterate_prompt.value,context_prompt.value, conversation_dropdown)\n",
    "                else:\n",
    "                    response = call_openai_api(messages, temp)\n",
    "                    assistant_response = response.choices[0].message \n",
    "                    \n",
    "                if assistant_response.role == \"assistant\":\n",
    "                    print('Model Response: ', assistant_response.content)\n",
    "                    \n",
    "                    suggested_solution = parse_solution(assistant_response.content)\n",
    "\n",
    "                    if suggested_solution is not None:\n",
    "                        (lab_result,TrainingDat) = find_matching_result(formulation_df, suggested_solution)\n",
    "                        if lab_result:\n",
    "                            current_strength = lab_result\n",
    "                            print(TrainingDat)\n",
    "                            training_data.append(f\"{TrainingDat} resulted in a strength of {current_strength} MPa.\")\n",
    "                            #print('######TrainingData',training_data)\n",
    "                            valid_solution = True\n",
    "                            \n",
    "                            print('The suggested formulation achieved a strength of ', current_strength, ' MPa.')\n",
    "                        else:\n",
    "                            print(f\"Iteration {iterations}: No matching lab result found for suggestion {suggested_solution}\")\n",
    "                    else:\n",
    "                        print(f\"Iteration {iterations}: Assistant's response did not contain a valid solution. Trying again.\")\n",
    "\n",
    "                    if not valid_solution:\n",
    "                        messages[-1][\"content\"] = iterate_prompt.value + \"\\nRemember the exact parameter grid: Powderkg: {360, 370, 380, 390,400, 410, 420, 430, 440, 450}, wc: {0.45, 0.5, 0.55, 0.6}, materials: {0.7/0.3, 0.6/0.4, 0.5/0.5}, curing: {ambient, heat}. Please stick to these values and the following format: 'The formulation is Powderkg = {your estimate}, wc = {your estimate}, materials = {your estimate}, curing = {your estimate}'\"\n",
    "                else:\n",
    "                    print(f\"Iteration {iterations}: Response not from 'assistant'. Trying again.\")\n",
    "\n",
    "            if current_strength >= desired_strength:\n",
    "                print(f\"\\nDesired compressive strength of {desired_strength} MPa achieved after {iterations} iterations. The solution is {suggested_solution}.\")\n",
    "                break\n",
    "\n",
    "        timestamp = str(int(time.time()))\n",
    "\n",
    "        # create the file name\n",
    "        filename = f\"Results/LLM/{model_dropdown.value}_{prompt_dropdown.value}_prompt_experiment_{experiment+1}_temp_{temp}_target_{int(targ_quant.value)}_%_Dev_Budget_{budget}_recursive_{enable_TVDL_strategy}_{timestamp}.csv\"\n",
    "       \n",
    "        # open the file in write mode\n",
    "        with open(filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # write the headers\n",
    "            writer.writerow([\"Formulation\", \"Compressive Strength\"])\n",
    "\n",
    "            # iterate over the training data\n",
    "            for data in training_data:\n",
    "                try:\n",
    "                    # parse the data to extract formulation and compressive strength\n",
    "                    formulation, strength_str = data.split(\" resulted in a strength of \")\n",
    "                    strength = float(strength_str.split(\" \")[0])  # convert string to float\n",
    "                    writer.writerow([formulation, strength])\n",
    "                except ValueError as e:\n",
    "                    print(f\"Failed to parse data: {data}\")\n",
    "                    print(f\"Error: {e}\")\n",
    "\n",
    "        print(f\"Data for experiment {experiment+1} and temp {temp} successfully saved to {filename}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707b366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
