{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c161ee3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuring\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterials\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(parse_curing)  \u001b[38;5;66;03m# Add this line\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 78\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/DiscoveryData_Sample.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Initialize empty DataFrame\u001b[39;00m\n\u001b[1;32m     81\u001b[0m formulation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormulation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStrength\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(csv_path)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(csv_path):\n\u001b[0;32m---> 73\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n\u001b[1;32m     74\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFA_GGBFS_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterials\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(parse_materials)\n\u001b[1;32m     75\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuring\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterials\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(parse_curing)  \u001b[38;5;66;03m# Add this line\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Map the dropdown value to enable_TVDL_strategy\n",
    "if TT.value == '3':\n",
    "    enable_TVDL_strategy = 1\n",
    "elif TT.value == '1':\n",
    "    enable_TVDL_strategy = 0\n",
    "elif TT.value == '5':\n",
    "    enable_TVDL_strategy = 2\n",
    "\n",
    "def find_matching_result(df, suggestion):\n",
    "    if suggestion:\n",
    "        # Create the suggestion string in the same format as the formulation strings\n",
    "        suggestion_str = f'The formulation is Powderkg = {suggestion[\"powderkg\"]}, wc = {suggestion[\"wc\"]}, materials = {suggestion[\"materials\"]}, curing = {suggestion[\"curing\"]}'\n",
    "        TrainingDat = f'Powderkg = {suggestion[\"powderkg\"]}, wc = {suggestion[\"wc\"]}, materials = {suggestion[\"materials\"]}, curing = {suggestion[\"curing\"]}'\n",
    "        \n",
    "        # Look for a match in the DataFrame\n",
    "        match = df[df[\"Formulation\"].str.lower() == suggestion_str.lower()]\n",
    "        \n",
    "        # If a match was found, return the lab result and TrainingDat\n",
    "        if not match.empty:\n",
    "            return match.iloc[0][\"Strength\"], TrainingDat\n",
    "        \n",
    "        # If no match was found, print the suggestion string for debugging\n",
    "        else:\n",
    "            print(\"No match found for suggestion string: \", suggestion_str)\n",
    "\n",
    "    # If no suggestion provided or no match found, return None\n",
    "    return None, None\n",
    "\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "def parse_solution(response):\n",
    "    # Initialize a dictionary to hold the solution\n",
    "    solution = {}\n",
    "\n",
    "    # Function to normalize key names\n",
    "    def normalize_key(key):\n",
    "        # Normalize common variations to a standard form\n",
    "        key_map = {\n",
    "            'powderkg': 'powderkg',\n",
    "            'wc': 'wc',\n",
    "            'materials': 'materials',\n",
    "            'curing': 'curing'\n",
    "        }\n",
    "        for known_key, normalized_key in key_map.items():\n",
    "            if known_key in key.lower().replace(\" \", \"\"):\n",
    "                return normalized_key\n",
    "        return None\n",
    "\n",
    "    # Try to parse the response as JSON\n",
    "    try:\n",
    "        json_data = json.loads(response)\n",
    "        for key, value in json_data.items():\n",
    "            normalized_key = normalize_key(key)\n",
    "            if normalized_key:\n",
    "                solution[normalized_key] = str(value)\n",
    "        if solution:  # If we successfully extracted data\n",
    "            return solution\n",
    "    except json.JSONDecodeError:\n",
    "        # If JSON parsing fails, proceed with regex parsing for the plain text format\n",
    "        keys = ['powderkg', 'wc', 'materials', 'curing']  # Updated to include 'curing'\n",
    "        for key in keys:\n",
    "            if key != 'curing':  # For 'curing', we might need a different approach\n",
    "                match = re.search(fr\"{key} = (.*?)(,|$)\", response, re.IGNORECASE)\n",
    "                if match:\n",
    "                    value = match.group(1).strip()\n",
    "                    solution[key] = value\n",
    "                else:\n",
    "                    # If any key wasn't found using regex, return None\n",
    "                    return None\n",
    "            else:\n",
    "                # Handle 'curing' specifically based on the presence of keywords\n",
    "                if \"ambient\" in response.lower():\n",
    "                    solution[\"curing\"] = \"Ambient curing\"\n",
    "                elif \"heat\" in response.lower():\n",
    "                    solution[\"curing\"] = \"Heat curing\"\n",
    "                else:\n",
    "                    # If 'curing' condition is not met, return None\n",
    "                    return None\n",
    "        return solution  # Return the solution dictionary if all keys were found with regex\n",
    "\n",
    "    # Return None if neither JSON nor regex parsing succeeded\n",
    "    return None\n",
    "\n",
    "    \n",
    "def format_response_to_model(lab_result):\n",
    "    \"\"\"\n",
    "    Given a lab result, format a response message to the model.\n",
    "    \"\"\"\n",
    "    return f\"We've achieved a compressive strength of {lab_result['fc_28d_Lab_validation']} MPa. Let's try to do better!\"\n",
    "\n",
    "def parse_materials(materials_str):\n",
    "    match = re.search(r'(\\d+)/(\\d+) FA/GGBFS', materials_str)\n",
    "    if match:\n",
    "        return int(match.group(1)) / (int(match.group(1)) + int(match.group(2)))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def parse_curing(materials_str):\n",
    "    if \"Ambient curing\" in materials_str:\n",
    "        return \"ambient\"\n",
    "    elif \"Heat curing\" in materials_str:\n",
    "        return \"oven\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['FA_GGBFS_ratio'] = df['Materials'].apply(parse_materials)\n",
    "    df['curing'] = df['Materials'].apply(parse_curing)  # Add this line\n",
    "    return df\n",
    "\n",
    "df = load_data('Data/DiscoveryData_Sample.csv')\n",
    "\n",
    "# Initialize empty DataFrame\n",
    "formulation_df = pd.DataFrame(columns=[\"Formulation\", \"Strength\"])\n",
    "\n",
    "# Loop through each row in the original data\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    # Get necessary attributes from row\n",
    "    powder = row[\"Powderkg\"]\n",
    "    wc = row[\"WC\"]\n",
    "    materials = row[\"Materials\"]\n",
    "\n",
    "    # Extract Fly Ash/GGBFS ratio\n",
    "    fa_ggbfs = materials.split(\",\")[0].split(\"-\")[1]\n",
    "    \n",
    "    # Extract curing method\n",
    "    curing_method = materials.split(\",\")[-1].strip()\n",
    "\n",
    "    # Remove unwanted string from curing method\n",
    "    curing_method = curing_method.replace(\" (Rao et al. 2018)\", \"\")\n",
    "    curing_method = curing_method.replace(\" (Rao et al.)\", \"\")\n",
    "    \n",
    "    # Compressive strength\n",
    "    strength = row[\"fc_28dGroundTruth\"]\n",
    "    \n",
    "    # Create formulation string in the same format as the model's output\n",
    "    formulation = f'The formulation is Powderkg = {powder}, wc = {wc}, materials = {fa_ggbfs}, curing = {curing_method}'\n",
    "    \n",
    "    # Append the formulation and its respective strength to the new DataFrame\n",
    "    new_row = pd.DataFrame({\"Formulation\": [formulation], \"Strength\": [strength]})\n",
    "    formulation_df = pd.concat([formulation_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "def handle_openai_error(exception):\n",
    "    if isinstance(exception, openai.error.RateLimitError):\n",
    "        print(f\"Rate limit error. Will retry after {exception.wait_seconds} seconds.\")\n",
    "        time.sleep(exception.wait_seconds)\n",
    "    elif isinstance(exception, openai.error.InvalidRequestError):\n",
    "        print(f\"Invalid request: {str(exception)}\")\n",
    "    elif isinstance(exception, openai.error.AuthenticationError):\n",
    "        print(f\"Authentication error: {str(exception)}\")\n",
    "    elif isinstance(exception, openai.error.ServiceUnavailableError):\n",
    "        print(f\"Service unavailable error. Retrying after a delay...\")\n",
    "        time.sleep(5)  # Sleep for 5 seconds before retrying\n",
    "    elif isinstance(exception, openai.error.APIError):\n",
    "        print(f\"API error: {str(exception)}. Retrying after a delay...\")\n",
    "        time.sleep(5)  # Sleep for 5 seconds before retrying\n",
    "    elif isinstance(exception, openai.error.Timeout):\n",
    "        print(f\"Timeout error: {str(exception)}. Retrying after a longer delay...\")\n",
    "        time.sleep(10)  # Sleep for 10 seconds before retrying\n",
    "    else:\n",
    "        raise exception\n",
    "        \n",
    "# -> here we also set the API parameters, such as temperature, etc.\n",
    "\n",
    "def call_openai_api(messages,temp, max_retries=5, delay=5):\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model= model_dropdown.value,\n",
    "                temperature=temp,\n",
    "                messages=messages,\n",
    "                max_tokens=500,\n",
    "                n=1\n",
    "            )\n",
    "            return response\n",
    "        except openai.error.OpenAIError as e:\n",
    "            \n",
    "            handle_openai_error(e)\n",
    "            if i < max_retries - 1:  # i is zero indexed\n",
    "                time.sleep(delay)  # wait before trying again\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "# Load the text from the file\n",
    "if  prompt_dropdown.value == 'None 0':\n",
    "    with open('Prompts/prompts_ID_none 0.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Generic 0':\n",
    "    with open('Prompts/prompts_ID_generic 0.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Specific 0':\n",
    "    with open('Prompts/prompts_ID_specific 0.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif  prompt_dropdown.value == 'None 1':\n",
    "    with open('Prompts/prompts_ID_none 1.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Generic 1':\n",
    "    with open('Prompts/prompts_ID_generic 1.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Specific 1':\n",
    "    with open('Prompts/prompts_ID_specific 1.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif  prompt_dropdown.value == 'None 2':\n",
    "    with open('Prompts/prompts_ID_none 2.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Generic 2':\n",
    "    with open('Prompts/prompts_ID_generic 2.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "elif prompt_dropdown.value == 'Specific 2':\n",
    "    with open('Prompts/prompts_ID_specific 2.txt', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "  \n",
    "# Store the contents in separate variables\n",
    "#instructions_text = lines[0]\n",
    "DA_role_text = lines[0]\n",
    "context_text = lines[1]\n",
    "iterate_text = lines[2]\n",
    "VM_role_text = lines[3]\n",
    "\n",
    "\n",
    "  \n",
    "# Create the widgets with the loaded text\n",
    "layout = widgets.Layout(width='auto', height='200px')  # adjust the height and width as needed\n",
    "#instructions_prompt = widgets.Textarea(value=instructions_text, description='Instructions:', layout=layout)\n",
    "DA_role_prompt = widgets.Textarea(value=DA_role_text, description='DA Instuctions:', layout=layout)\n",
    "VM_role_prompt = widgets.Textarea(value=VM_role_text, description='VM Instuctions:', layout=layout)\n",
    "context_prompt = widgets.Textarea(value=context_text, description='Design Knowledge:', layout=layout)\n",
    "\n",
    "iterate_prompt = widgets.Textarea(value=iterate_text, description='User:', layout=layout)\n",
    "\n",
    "\n",
    "# Run to display the text box widgets and the save button\n",
    "\n",
    "# Set the 'flex' property for each widget inside main_layout\n",
    "iterate_prompt.layout.flex = '2'       # Adjust the value as needed\n",
    "\n",
    "#Instructions_box = widgets.HBox([instructions_prompt],layout=widgets.Layout(width='100%', height='100px'))\n",
    "Iterate_box = widgets.HBox([iterate_prompt],layout=widgets.Layout(width='100%', height='100px'))\n",
    "\n",
    "title = widgets.HTML(\"<h2>Main Prompts</h2>\")\n",
    "Prompts = widgets.VBox([title ,DA_role_prompt, VM_role_prompt, Iterate_box, context_prompt])\n",
    "\n",
    "temperatures_str = model_temperatures.value\n",
    "# Split the string using commas as a delimiter and convert to float numbers\n",
    "temperatures = [float(t) for t in temperatures_str.split(',')]\n",
    "budget = num_development.value\n",
    "NrOfExper = num_experiments.value\n",
    "\n",
    "desired_strength = formulation_df[\"Strength\"].quantile(targ_quant.value/100)\n",
    "\n",
    "num_entries_above_desired = (formulation_df[\"Strength\"] >= desired_strength).sum()\n",
    "\n",
    "# Print the result\n",
    "\n",
    "print('SUMMARY\\n' +'The design target is to achieve a strength of ',desired_strength, 'MPa within ',num_development.value,' development cycles.\\n' +\n",
    "      'The Experiment is repeated ',num_experiments.value,' times using the ',model_dropdown.value, ' model and the prompt strategy: ',prompt_dropdown.value,'.')\n",
    "print(\"There are \", num_entries_above_desired,' formulations above or equal to desired_strength.')\n",
    "\n",
    "\n",
    "def extract_formulations_from_training_data(training_data):\n",
    "    pattern = re.compile(r'Powderkg\\s*=\\s*(\\d+),\\s*wc\\s*=\\s*(\\d+\\.\\d+),\\s*materials\\s*=\\s*(\\d+\\.\\d+/\\d+\\.\\d+),\\s*curing\\s*=\\s*(\\w+)', re.IGNORECASE)\n",
    "    training_formulations = [match.group(0) for data in training_data for match in [pattern.search(data)] if match]\n",
    "    return training_formulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9ff5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
